{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9939f6-1a27-49ca-8764-5b61954f1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "559c6be5-d52a-4c30-9346-e31573d7a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Yelp Fusion API Key\n",
    "API_KEY = #use your own API Key\n",
    "\n",
    "# Define the radius (in meters)\n",
    "radius = 4000  # 40 km\n",
    "\n",
    "# Set the total limit of entries to scrape (200)\n",
    "total_scraped_limit = 200\n",
    "\n",
    "\n",
    "incremental_scraped_limit = 50  # This is the max for each request\n",
    "\n",
    "# List of coordinates (latitude, longitude) for major cities in Ontario\n",
    "ontario_locations = [\n",
    "    (43.73, -79.63), # Vaughan\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "60167ece-b812-420f-a632-c4f9b6380f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plumber_data(latitude, longitude, radius, current_total, incremental_limit):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "    }\n",
    "\n",
    "    # Yelp API endpoint for business search\n",
    "    url = 'https://api.yelp.com/v3/businesses/search'\n",
    "\n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'term': 'Phone Repair',\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'radius': radius,\n",
    "        'limit': incremental_limit,\n",
    "        'offset': current_total,  # Start fetching after the current total\n",
    "    }\n",
    "\n",
    "    all_entries = []\n",
    "    \n",
    "    while current_total < total_scraped_limit:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching data: {response.json()}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        businesses = data.get('businesses', [])\n",
    "\n",
    "        # Add businesses to the all_entries list\n",
    "        all_entries.extend(businesses)\n",
    "        current_total += len(businesses)\n",
    "\n",
    "        # Check if there's a need to make another request\n",
    "        if len(businesses) < incremental_limit:\n",
    "            break  # No more results available\n",
    "\n",
    "        # Update offset for the next request\n",
    "        params['offset'] = current_total\n",
    "        time.sleep(1)  # Sleep for a second to avoid rate limiting\n",
    "\n",
    "    return all_entries[:total_scraped_limit]  # Return up to total_scraped_limit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "3afa00ab-3cbf-423d-937c-7270ec881e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(entries, filename):\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as csv_file:  # Append mode\n",
    "        fieldnames = ['Name', 'Rating', 'Number of Reviews', 'Opening Hours', 'Phone Number', \n",
    "                      'Address', 'Website', 'Response Time', 'Response Rate', 'Services Provided', \n",
    "                      'Profile Link', 'Location', 'Service Tag']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Only write header if the file is being created\n",
    "        if csv_file.tell() == 0:\n",
    "            writer.writeheader()  # Write header to CSV if file is empty\n",
    "        \n",
    "        # Loop through each entry and write the details to the CSV\n",
    "        for entry in entries:\n",
    "            name = entry.get('name', 'N/A')\n",
    "            rating = entry.get('rating', 'N/A')\n",
    "            num_reviews = entry.get('review_count', 'N/A')\n",
    "            phone_number = entry.get('display_phone', 'N/A')\n",
    "            address = \", \".join(entry.get('location', {}).get('display_address', []))\n",
    "            website = entry.get('url', 'N/A')\n",
    "            \n",
    "            # Opening hours\n",
    "            if 'hours' in entry and entry['hours']:\n",
    "                opening_hours = []\n",
    "                for hour in entry['hours']:\n",
    "                    for open_time in hour['open']:\n",
    "                        opening_hours.append(f\"{open_time['day']}: {open_time['start']} - {open_time['end']}\")\n",
    "                opening_hours = \"; \".join(opening_hours)\n",
    "            else:\n",
    "                opening_hours = 'N/A'\n",
    "            \n",
    "            # Get response time and response rate (if available)\n",
    "            response_time = entry.get('attributes', {}).get('response_time', 'N/A')\n",
    "            response_rate = entry.get('attributes', {}).get('response_rate', 'N/A')\n",
    "            \n",
    "            # Get services provided\n",
    "            services_provided = entry.get('categories', [])\n",
    "            services_provided = \", \".join([service['title'] for service in services_provided])\n",
    "            \n",
    "            # Profile link\n",
    "            profile_link = entry.get('url', 'N/A')\n",
    "            \n",
    "            # Location tag (e.g., what the service provider is known for)\n",
    "            service_tag = entry.get('alias', 'N/A')\n",
    "\n",
    "            # Write data to the CSV file\n",
    "            writer.writerow({\n",
    "                'Name': name,\n",
    "                'Rating': rating,\n",
    "                'Number of Reviews': num_reviews,\n",
    "                'Opening Hours': opening_hours,\n",
    "                'Phone Number': phone_number,\n",
    "                'Address': address,\n",
    "                'Website': website,\n",
    "                'Response Time': response_time,\n",
    "                'Response Rate': response_rate,\n",
    "                'Services Provided': services_provided,\n",
    "                'Profile Link': profile_link,\n",
    "                'Location': address,\n",
    "                'Service Tag': service_tag\n",
    "            })\n",
    "\n",
    "    print(f\"New data has been appended to '{filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ae4604a7-6a9f-40c9-a3c1-8b0da496c8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total new entries retrieved from (43.73, -79.63): 12\n",
      "New data has been appended to 'plumbers_data_yelp.csv'\n",
      "No more new entries available for location (43.73, -79.63).\n",
      "Total entries scraped: 12\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    total_entries_scraped = 0\n",
    "    \n",
    "    # Initialize the CSV file with headers (run this only once to create the file)\n",
    "    with open('plumbers_data_yelp.csv', mode='w', newline='', encoding='utf-8') as csv_file:\n",
    "        fieldnames = ['Name', 'Rating', 'Number of Reviews', 'Opening Hours', 'Phone Number', \n",
    "                      'Address', 'Website', 'Response Time', 'Response Rate', 'Services Provided', \n",
    "                      'Profile Link', 'Location', 'Service Tag']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()  # Write header to CSV\n",
    "\n",
    "    for latitude, longitude in ontario_locations:\n",
    "        while total_entries_scraped < total_scraped_limit:\n",
    "            # Get additional plumber data\n",
    "            new_plumber_entries = get_plumber_data(latitude, longitude, radius, total_entries_scraped, incremental_scraped_limit)\n",
    "\n",
    "            # Count the number of new entries retrieved\n",
    "            new_entries_count = len(new_plumber_entries)\n",
    "            total_entries_scraped += new_entries_count\n",
    "\n",
    "            print(f\"Total new entries retrieved from ({latitude}, {longitude}): {new_entries_count}\")\n",
    "            \n",
    "            # Save new data to CSV\n",
    "            if new_entries_count > 0:  # Only save if new entries exist\n",
    "                save_to_csv(new_plumber_entries, 'plumbers_data_yelp.csv')\n",
    "\n",
    "            # Break if no new entries are retrieved\n",
    "            if new_entries_count < incremental_scraped_limit:\n",
    "                print(f\"No more new entries available for location ({latitude}, {longitude}).\")\n",
    "                break\n",
    "\n",
    "    print(f\"Total entries scraped: {total_entries_scraped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d1225-57d0-465e-902c-1ecca92674a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
